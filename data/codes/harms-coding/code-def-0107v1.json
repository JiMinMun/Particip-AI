
{"manipulate-people": "Harm that misleads people to make choices that do not benefit them and is deceptive or fraudulent",
"misinformation": "Harm that causes people to believe in false information or incorrect state of the world by intentionally providing misleading knowledge, i.e., spreading misinformation",
"bias": "Infringement of social justice by spreading prejudice and bias",
"mental-harm": "Mentally harm or upsets people by hurtful outputs and spread of negative information",
"overreliance": "People becoming dependent on technology and overtrusting and overrelying on them leading to diminished abilities to complete the task",
"physical-harm": "Technology leads to physical harm such as injuries and deaths",
"war": "Technology is used for wars or leads to wars and physical harm at a societal or global level",
"economic-disturbance": "Technology causing wider economic harms and disturbances such as widespread job loss or depression",
"financial-disturbance": "Technology causing more individual or smaller scale financial loss or property damage",
"human-labor-replacement": "Technology causes job loss and replacement of human labor force causing unemployment",
"social-isolation": "Technology causes weakened interpersonal connection especiallh with family and friends leading to isolation",
"range": "Technology causes a range of harms from very small impact to serious and more wide-spread harms",
"aid-criminal": "Technology is used to aid criminal activity",
"distrust-ai": "Technology or complicated output leads to distrust or underuse of the AI application",
"distrust-institution": "Technology leads to distrust of institutions such as the healthcare system",
"data-security-privacy-risk": "Privacy is invaded or data is lost through the use of technology or data is used in a negative way to benefit other stakeholders rather than the user",
"plagirism": "Technology plagirizes the existing work or copyrighted work",
"damaging-creativity": "Technology damages creativity or leads to unoriginality",
"hinder-career": "Technology causes career damage",
"incorrect-ai-output": "AI output being unintentionally incorrect or erroneous leads to different harms to users such as misdiagnosis or incorrect advice",
"legal-issues": "AI causing legal issues such as law suits due to illegal outputs",
"impede-learning": "AI causes people to not learn or grow as much",
"social-division": "AI causes social division and leads societal spread of hate or distrust",
"extinction": "AI leads to extinction of some sort such as group of people, human race, other animals, or culture",
"minority": "AI leads to harming minority or underrepresente groups",
"waste-resources-or-time": "Technology leads to wasting resources such as time in development and is useless",
"unqualified-accessibility": "Technology makes certain tasks too easy so that non-qualified people or bad actors have better accessibility to these tasks",
"terrorism": "Technology leads to aiding terrorists, for example, in making weapons or bombs",
"business-use": "Technology is used by businesses to maximize profit",
"non-war-military-use": "Technology is used by the military for non-war purposes",
"lower-quality": "Technology lowers the quality by making mistakes or creating homogenious outputs, which are worse than human work",
"information-access": "Technology prevents access to information",
"general-harm": "Risks security through lack of safety checks or the application is rendered unsafe and can harm or hurt users in unspecified ways",
"hinder-science": "Hinders scientific breakthroughs",
"no-harm": "No harms caused",
"miscommunication": "The use of application leads to miscommunication",
"negative-health-wellbeing": "Technology causes negative health outcome",
"hinder-medical-care": "Technology causes hindrance to medical and healthcare advancement and application",
"environmental-harm": "Causes environmental harm or allows continued environmental harm such as climate change",
"hacking-risk": "AI could be hacked by bad actors to be used for malicious tasks",
"new-code": "None of the above codes apply but the answer is still meaningful, so a new code is needed",
"na": "The participant answer does not make sense in the context"}